# Default values for slm-server.

replicaCount: 1

image:
  repository: x3huang/slm-server
  pullPolicy: IfNotPresent
  # Overridden by the CI/CD pipeline
  tag: ""

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""

service:
  type: ClusterIP
  port: 8000

# ServiceMonitor configuration for Prometheus
serviceMonitor:
  enabled: true
  path: /metrics
  interval: 71s
  scrapeTimeout: 30s
  labels: {}
  annotations: {}
  relabelings: []
  metricRelabelings: []

persistence:
  enabled: true
  # The absolute path on the host node where the model data is stored.
  hostPath: "/mnt/disks/ssd1/slm-data"
  # The name of the node where the storage is located.
  # This should be left empty and set during deployment.
  # nodeName: ""
  accessMode: ReadWriteOnce
  size: 5Gi # Adjust based on your model size
  mountPath: /app/models

# We are not using ingress or hpa for now
ingress:
  enabled: false

hpa:
  enabled: false

# This section is for setting up autoscaling more information can be found here: https://kubernetes.io/docs/concepts/workloads/autoscaling/
autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

# Environment variables to inject into the container
# Example configuration for SLM server settings
env: {}
  # Application settings
  # SLM_MODEL_PATH: "/app/models/Qwen3-0.6B-Q4_K_M.gguf"
  # SLM_N_CTX: "4096"
  # SLM_N_THREADS: "2"
  # SLM_SEED: "42"
  # SLM_S_TIMEOUT: "1"
  
  # Logging settings
  # SLM_LOGGING__VERBOSE: "true"
  
  # Tracing settings
  # SLM_TRACING__ENABLED: "true"
  # SLM_TRACING__ENDPOINT: "https://tempo.example.com/api/traces"
  # SLM_TRACING__USERNAME: "your-username"
  # SLM_TRACING__PASSWORD: "your-password"

# Resource requests and limits for the container.
# See https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
#
# Memory budget breakdown (target node: 1-CPU / 2 GB VPS):
#   Chat LLM  – Qwen3-0.6B-Q4_K_M.gguf       ~484 MB (4-bit quantised)
#   Embedding – all-MiniLM-L6-v2 quint8 ONNX   ~23 MB (uint8 AVX2 quantised)
#   KV cache  – n_ctx=2048                     ~50-80 MB
#   Runtime   – Python, FastAPI, onnxruntime   ~50-100 MB
#   -------------------------------------------------------
#   Total request: 550 Mi   Hard limit: 1 Gi
#
# Why these models:
#   - Qwen3-0.6B-Q4_K_M is the smallest instruction-tuned LLM that still
#     supports function calling (chatml format) at usable quality.
#   - all-MiniLM-L6-v2 (384-dim, 6-layer) is purpose-trained for sentence
#     embeddings via mean pooling, ranking well on STS benchmarks for its
#     size. The quint8 AVX2 variant keeps the file at 23 MB vs 90 MB fp32.
#
# Why the limit is reasonable:
#   - The worker node (active-nerd-2) has 2 GiB total RAM shared with the
#     OS and other pods. 550 Mi request leaves headroom; the 1 Gi hard
#     limit prevents OOM-kill from bursty KV-cache growth.
#   - MAX_CONCURRENCY=1 ensures only one inference runs at a time, so peak
#     memory is predictable (no concurrent KV-cache allocations).
resources:
  limits:
    cpu: 900m
    memory: 1Gi
  requests:
    cpu: 50m
    memory: 550Mi

# Readiness and liveness probes configuration
probes:
  readiness:
    enabled: true
    path: /health
    initialDelaySeconds: 10
    periodSeconds: 70
    timeoutSeconds: 30
    successThreshold: 1
    failureThreshold: 5
  liveness:
    enabled: true
    path: /health
    initialDelaySeconds: 30
    periodSeconds: 70
    timeoutSeconds: 30
    successThreshold: 1
    failureThreshold: 5

# Content is injected at deploy time via: --set-file "configMapData.download\.sh=scripts/download.sh"
configMapData: {}

# Volumes and volumeMounts rendered via tpl so template expressions work.
volumes:
  - name: models-storage
    persistentVolumeClaim:
      claimName: '{{ include "slm-server.fullname" . }}'
  - name: scripts
    configMap:
      name: '{{ include "slm-server.fullname" . }}-scripts'
      defaultMode: 0755

volumeMounts:
  - name: models-storage
    mountPath: /app/models

initContainers:
  - name: download-model
    image: curlimages/curl:latest
    command: ["sh", "-c", "MODEL_DIR=/app/models sh /scripts/download.sh"]
    volumeMounts:
      - name: models-storage
        mountPath: /app/models
      - name: scripts
        mountPath: /scripts

strategy:
  type: Recreate
